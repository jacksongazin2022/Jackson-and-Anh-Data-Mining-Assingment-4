{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20ad65b",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afe8befa-30dd-4af5-995f-a8309cdfe639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "import my_utils\n",
    "import gzip\n",
    "import shutil\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fd8c97-6e72-47c6-bee6-2a807d532e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_gz_file = '../Output/GSE185948_count_RNA.rds.gz'\n",
    "output_rds_file = '../Output/data_for_r.rds'\n",
    "\n",
    "# Open the compressed file and extract it\n",
    "with gzip.open(input_gz_file, 'rb') as f_in, open(output_rds_file, 'wb') as f_out:\n",
    "    shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(f'{input_gz_file} has been successfully uncompressed to {output_rds_file}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77773596-d217-481d-90eb-cff1fe9563ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_gz_file = '../Output/GSE185948_metadata_RNA.csv.gz'\n",
    "output_csv_file = '../Output/uncompressed_metadata.csv'\n",
    "\n",
    "# Open the compressed file and extract it\n",
    "with gzip.open(input_gz_file, 'rb') as f_in, open(output_csv_file, 'wb') as f_out:\n",
    "    shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(f'{input_gz_file} has been successfully uncompressed to {output_csv_file}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd10524-abd6-4eda-8ea8-9d53cff8d84c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_path = '../Output'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d033d150-def7-422c-b556-cfadb89c76db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('../Output/uncompressed_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db12762e-d950-4f0d-88ae-cd32ec8e43ca",
   "metadata": {},
   "source": [
    "R code below"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea593dcf-f6ef-476e-97fa-5527db6fb58a",
   "metadata": {},
   "source": [
    "filename = file.choose()\n",
    "data = readRDS(filename)\n",
    "data\n",
    "sparse_matrix <- data\n",
    "\n",
    "num_columns <- ncol(sparse_matrix)\n",
    "# Get the nonzero elements and their indices\n",
    "nonzero_elements <- sparse_matrix@x\n",
    "row_indices <- sparse_matrix@i\n",
    "col_indices <- rep(1:num_columns, times = diff(sparse_matrix@p))  # Use sparse_matrix@j for column indices\n",
    "\n",
    "\n",
    "nonzero_data <- data.frame(row_indices, col_indices, nonzero_elements)\n",
    "\n",
    "col_names <- data.frame(sparse_matrix@Dimnames[2])\n",
    "nrow(col_names)\n",
    "row_names <- data.frame((sparse_matrix@Dimnames[1]))\n",
    "\n",
    "write.csv(row_names, 'row_names.csv')\n",
    "write.csv(col_names, 'col_names.csv')\n",
    "\n",
    "\n",
    "# Save the i, j information to a Parquet file\n",
    "write_parquet(nonzero_data, \"non_zero.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c87489-add6-4698-bc23-884af1dcaf8c",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d881cd-1a18-43f9-84d1-ff85e77ef9db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install --upgrade --no-deps memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d363c1-327c-4470-b520-af645a113edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '../Output/non_zero.parquet'\n",
    "row_info_path = '../Output/row_names.csv'\n",
    "column_info_path = '../Output/col_names.csv'\n",
    "#sparse_matrix = coo_matrix((data['nonzero_elements'], (data['row_indices'], data['col_indices'])))\n",
    "sparse_matrix, column_names, row_names, row_indices= my_utils.load_data(data_path, row_info_path, column_info_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb6927-abb7-4961-a2b4-3447d71d8234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_pipeline = Pipeline([\n",
    "    ('splitter', my_utils.SparseTrainTestSplit(test_size=0.2, random_state=42, row_indices = row_indices)),\n",
    "    # Add other steps in the pipeline as needed\n",
    "])\n",
    "\n",
    "# Fit and transform the pipeline\n",
    "sparse_train, sparse_test, train_indices, test_indices = split_pipeline.fit_transform(sparse_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f17eec-f7e8-4790-b8f1-bd978367b2e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sparse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfeb12c-ab56-424c-a09a-62dd30fc2494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_and_pca_pipeline = Pipeline([\n",
    "    ('cleaner', my_utils.DataClean()),  # CleanData is performed first\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('pca', TruncatedSVD(n_components=2))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to training\n",
    "clean_and_pca_pipeline.fit(sparse_train)\n",
    "# Transform the training data\n",
    "pca_sparse_train = clean_and_pca_pipeline.transform(sparse_train)\n",
    "\n",
    "pca_sparse_test = clean_and_pca_pipeline.transform(sparse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abcfad5-2055-4bd5-ac33-6cda5241999f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reindexer = my_utils.Reindex(columns=[\"PC1\", \"PC2\"], names=row_names, output_folder=\"../Output\")\n",
    "train_pca_df = reindexer.transform(pca_sparse_train, train_indices, \"train\")\n",
    "test_pca_df = reindexer.transform(pca_sparse_test, test_indices, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ce4aee-7198-440b-90db-f654e038c82f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eda_pca = my_utils.DataEDAPCA(columns=[\"PC1\", \"PC2\"], trans=False, graphs=True)\n",
    "pca_train_df, metadata_empty, outlier_df = eda_pca.fit_transform(train_pca_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732968b-22a1-4c8a-9fab-057d6c4742b7",
   "metadata": {},
   "source": [
    "## Clustering on the Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b0fc11-1062-4743-8fec-51d9c7c635bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_train_df = pd.read_csv('../Output/pca_train_df_without_outliers.csv', index_col = 0)\n",
    "pca_test_df =  pd.read_csv('../Output/pca_test_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e768185-a84a-4629-a547-f6ade2bfc855",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Your existing code for HDBSCAN clustering\n",
    "hdbscan_params = {\n",
    "    'min_samples': [10, 30, 50, 60, 100],\n",
    "    'min_cluster_size': [100, 200, 300, 400, 500, 600],\n",
    "    'cluster_selection_method': ['eom', 'leaf'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "# Create a pipeline\n",
    "hdbscan_pipe = Pipeline([\n",
    "    (\"clusterer\", my_utils.Optimize_and_Compare_Hdbscan(hdbscan_params)),\n",
    "])\n",
    "\n",
    "results_hbd = hdbscan_pipe.fit(pca_train_df)\n",
    "best_estimator_hbd = results_hbd.named_steps['clusterer'].best_estimator\n",
    "\n",
    "try:\n",
    "    # Calculate silhouette score for test data\n",
    "    silhouette_test_hbd = silhouette_score(pca_test_df, best_estimator_hbd.fit_predict(pca_test_df))\n",
    "    print(f'Silhouette Score on test data: {silhouette_test_hbd}')\n",
    "except ValueError as e:\n",
    "    print(\"Only one cluster for my test data set. HDBSCAN does not work well for this data set\")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "silhouette_train_hbd = silhouette_score(pca_train_df, best_estimator_hbd.labels_)\n",
    "print(f'Silhouette Score on training data: {silhouette_train_hbd}')\n",
    "print(f'Time taken: {elapsed_time / 60:.2f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177b713-72e7-4faf-aed1-fa5b297c6519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_predictions = best_estimator_hbd.fit_predict(pca_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9e3975-d4e6-4b4a-b29a-4b0c657e661e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "kmeans_params = {\n",
    "    'n_clusters': list(range(1, 10)),\n",
    "    'init': ['random', 'k-means++'],\n",
    "    'n_init': [1, 5, 10],\n",
    "    'max_iter': [300],\n",
    "    'random_state': [0]\n",
    "}\n",
    "\n",
    "# Create a pipeline\n",
    "k_means_pipe = Pipeline([\n",
    "    (\"clusterer\", my_utils.OptimizeAndCompareKMeans(kmeans_params)),\n",
    "])\n",
    "\n",
    "results = k_means_pipe.fit(pca_train_df)\n",
    "best_estimator = results.named_steps['clusterer'].best_estimator\n",
    "predictions_test = best_estimator.predict(pca_test_df)\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Assuming you have already fitted the pipeline and obtained the best_estimator\n",
    "\n",
    "# For training data\n",
    "silhouette_train = silhouette_score(pca_train_df, best_estimator.labels_)\n",
    "\n",
    "# For test data\n",
    "silhouette_test = silhouette_score(pca_test_df, best_estimator.predict(pca_test_df))\n",
    "\n",
    "# Stop timing\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f'Silhouette Score on training data: {silhouette_train}')\n",
    "print(f'Silhouette Score on test data: {silhouette_test}')\n",
    "print(f'Time taken: {elapsed_time / 60:.2f} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27927a6a-82fa-41d8-ab50-3ebc71df5a65",
   "metadata": {},
   "source": [
    "I will use the Kmeans as my best estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f297064-e527-4a82-b833-83fbc13e88e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_df_untransposed = my_utils.create_labels_and_scoring_df(best_estimator, '../Output/best_estimator_untransposed_data_label_and_score', pca_train_df, pca_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e65cd3-c533-4b64-ac7a-fe142b255a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use your best_estimator to predict labels for the data\n",
    "cluster_labels = best_estimator.predict(pca_train_df)\n",
    "\n",
    "# Add the cluster_labels to the training data DataFrame\n",
    "pca_train_df['Cluster'] = cluster_labels\n",
    "\n",
    "# Create a scatter plot to visualize the clustering\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='PC1', y='PC2', data=pca_train_df, hue='Cluster', palette='viridis', s=50, alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Clustering Visualization')\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.legend(title='Cluster', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e22a4c4-a081-4085-92c8-e0c7b13a00ce",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/tuning-with-hdbscan-149865ac2970"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076af96-9d6f-4f0e-afa9-383cd9a3ea03",
   "metadata": {},
   "source": [
    "Things to consider\n",
    "\n",
    "\n",
    "1) Get the clustering to work in a pipeline\n",
    "2) Are these ok default parameters\n",
    "3) What to do with the test data\n",
    "4) Should we be using silhoute on grid search or should i be optimizaing it differently\n",
    "5) Are we normalizing it the right way? Since normalize is working along rows is this dealing with out of domain sampels? Just used standard scalar because no normalizers could work and some of them did along rows\n",
    "6) Make it so it put things in folders\n",
    "7) Quality check NAS? How do to this with a sparse matrix\n",
    "8) Do soemthing like she did in notebook 3 to label the data set\n",
    "9) Naive classifier and base? \n",
    "10) Would k-means be base what is naive?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519da77-d027-45c0-a89a-fe8ea229874f",
   "metadata": {},
   "source": [
    "Transposed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2300a8d0-76ef-46dd-8cc5-472d81e98d72",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ccb77b3-058c-42e7-9db5-895c2efed4d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning Transposed matrix, row_names of the transposed matrix, col_names of the transposed matrix, and row_indices of transposed matrix\n"
     ]
    }
   ],
   "source": [
    "data_path = '../Output/non_zero.parquet'\n",
    "row_info_path = '../Output/row_names.csv'\n",
    "column_info_path = '../Output/col_names.csv'\n",
    "#sparse_matrix = coo_matrix((data['nonzero_elements'], (data['row_indices'], data['col_indices'])))\n",
    "sparse_matrix_trans, row_names_trans, col_names_trans, row_indices_trans= my_utils.load_data(data_path, row_info_path, column_info_path, transpose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b8e4aa-3f31-4462-947a-7094119825ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_pipeline_trans = Pipeline([\n",
    "    ('splitter', my_utils.SparseTrainTestSplit(\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        row_indices=row_indices_trans\n",
    "    )),\n",
    "    # Add other steps in the pipeline as needed\n",
    "])\n",
    "\n",
    "# Fit and transform the pipeline\n",
    "(\n",
    "    sparse_train_trans,\n",
    "    sparse_test_trans,\n",
    "    train_indices_trans,\n",
    "    test_indices_trans\n",
    ") = split_pipeline_trans.fit_transform(sparse_matrix_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c358f-2ada-44fe-a1c5-4297d0b51b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row_names_df = pd.DataFrame(row_names_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6aed2b-53f6-4cc8-b703-7a4951f0b6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset_row_names_df = row_names_df.loc[train_indices_trans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a719969-c732-4a0d-9f3d-9dd4c8a7588f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset_row_names_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2153c-cee9-4f94-8013-f6e160aa200e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_indices_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a9de50-8e45-497b-a351-1248126e97a1",
   "metadata": {},
   "source": [
    "## Demographic Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348c3313-4b6d-4f76-a16b-8636ac15da1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_count = metadata['patient'].value_counts(normalize=True)\n",
    "cell_count.columns = ['patient', 'percentage']\n",
    "cell_count\n",
    "## Information on how much each patients account for total cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd67df1a-7008-449d-abb8-179a562a3f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_meta_data(row_names_list, train_indices, metadata):\n",
    "    # Create a DataFrame from the row_names_list with the 'name' column\n",
    "    row_names_df = pd.DataFrame(row_names_list, columns=['name'])\n",
    "\n",
    "    # Subset the row_names_df using the train_indices\n",
    "    subset_row_names_df = row_names_df.loc[train_indices]\n",
    "\n",
    "    # Subset the metadata to include only rows with 'name' values from subset_row_names_df\n",
    "    subset_metadata = metadata[metadata['name'].isin(subset_row_names_df['name'])]\n",
    "\n",
    "    return subset_metadata\n",
    "\n",
    "# Example usage of the function\n",
    "subsetted_metadata = get_training_meta_data(row_names_trans, train_indices_trans, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9391656e-185e-4bb0-a9ef-94810b2d3c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/vr7498696cv_y8s379054yf00000gn/T/ipykernel_15594/633631448.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  sampled_rows = subsetted_metadata[subsetted_metadata['gender'] == group_name[0]][subsetted_metadata['disease'] == group_name[1]].sample(n=sample_size, random_state=42)\n",
      "/var/folders/b0/vr7498696cv_y8s379054yf00000gn/T/ipykernel_15594/633631448.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  even_distribution_sample = even_distribution_sample.append(sampled_rows)\n",
      "/var/folders/b0/vr7498696cv_y8s379054yf00000gn/T/ipykernel_15594/633631448.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  sampled_rows = subsetted_metadata[subsetted_metadata['gender'] == group_name[0]][subsetted_metadata['disease'] == group_name[1]].sample(n=sample_size, random_state=42)\n",
      "/var/folders/b0/vr7498696cv_y8s379054yf00000gn/T/ipykernel_15594/633631448.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  even_distribution_sample = even_distribution_sample.append(sampled_rows)\n",
      "/var/folders/b0/vr7498696cv_y8s379054yf00000gn/T/ipykernel_15594/633631448.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  sampled_rows = subsetted_metadata[subsetted_metadata['gender'] == group_name[0]][subsetted_metadata['disease'] == group_name[1]].sample(n=sample_size, random_state=42)\n",
      "/var/folders/b0/vr7498696cv_y8s379054yf00000gn/T/ipykernel_15594/633631448.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  even_distribution_sample = even_distribution_sample.append(sampled_rows)\n",
      "/var/folders/b0/vr7498696cv_y8s379054yf00000gn/T/ipykernel_15594/633631448.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  sampled_rows = subsetted_metadata[subsetted_metadata['gender'] == group_name[0]][subsetted_metadata['disease'] == group_name[1]].sample(n=sample_size, random_state=42)\n",
      "/var/folders/b0/vr7498696cv_y8s379054yf00000gn/T/ipykernel_15594/633631448.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  even_distribution_sample = even_distribution_sample.append(sampled_rows)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have the 'subsetted_metadata' DataFrame\n",
    "group_counts = subsetted_metadata.groupby(['gender', 'disease']).size().reset_index(name='count')\n",
    "\n",
    "# Calculate the minimum count\n",
    "min_count = group_counts['count'].min()\n",
    "\n",
    "# Create an empty DataFrame to store the even distribution sample\n",
    "even_distribution_sample = pd.DataFrame(columns=subsetted_metadata.columns)\n",
    "\n",
    "# Randomly sample rows for each group\n",
    "for group_name, group_data in group_counts.groupby(['gender', 'disease']):\n",
    "    group_size = group_data['count'].iloc[0]\n",
    "    sample_size = min(min_count, group_size)\n",
    "    \n",
    "    # Randomly sample rows for the current group\n",
    "    sampled_rows = subsetted_metadata[subsetted_metadata['gender'] == group_name[0]][subsetted_metadata['disease'] == group_name[1]].sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Append the sampled rows to the even_distribution_sample DataFrame\n",
    "    even_distribution_sample = even_distribution_sample.append(sampled_rows)\n",
    "\n",
    "# Reset the index of the even_distribution_sample\n",
    "even_distribution_sample = even_distribution_sample.reset_index(drop=True)\n",
    "\n",
    "# Display the resulting DataFrame with an even distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fe5c188-b7f7-4bd7-82f3-db30ff816d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "balanced_name_list = even_distribution_sample['name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "607881d2-4c63-44c7-9ca4-ec4f799f98c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row_names_df = pd.DataFrame(row_names_trans, columns=['name'])\n",
    "subset_row_names_df = row_names_df.loc[train_indices_trans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72221027-cf60-40e2-8dbe-de5b02896709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of_balanced_incices = subset_row_names_df[subset_row_names_df['name'].isin(balanced_name_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9974ffb-405d-48a2-abe1-b073744a28a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47294</th>\n",
       "      <td>PKD_ACGTAACCACTGCACG-1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>PKD_ACGTCCTAGCTTAGTC-1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34455</th>\n",
       "      <td>PKD_GCTGCAGCATGTGCTA-1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88504</th>\n",
       "      <td>Cont_CGAGGCTAGCTGTTAC-1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12668</th>\n",
       "      <td>PKD_CATTGAGGTCCAACGC-1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>PKD_GTGTTAGCACGAAGAC-1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>PKD_TCATTGTTCAGCGCGT-1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>Cont_TGATCAGGTGATTCTG-1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>PKD_AGGCCACCACAACCGC-1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>PKD_GGAATGGAGCCAAGGT-1_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82168 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name\n",
       "47294   PKD_ACGTAACCACTGCACG-1_6\n",
       "10121   PKD_ACGTCCTAGCTTAGTC-1_2\n",
       "34455   PKD_GCTGCAGCATGTGCTA-1_4\n",
       "88504  Cont_CGAGGCTAGCTGTTAC-1_4\n",
       "12668   PKD_CATTGAGGTCCAACGC-1_2\n",
       "...                          ...\n",
       "6265    PKD_GTGTTAGCACGAAGAC-1_1\n",
       "54886   PKD_TCATTGTTCAGCGCGT-1_6\n",
       "76820  Cont_TGATCAGGTGATTCTG-1_2\n",
       "860     PKD_AGGCCACCACAACCGC-1_1\n",
       "15795   PKD_GGAATGGAGCCAAGGT-1_2\n",
       "\n",
       "[82168 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_row_names_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63a0e088-1013-4e9f-8425-630ffe4dddc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47294</th>\n",
       "      <td>PKD_ACGTAACCACTGCACG-1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34455</th>\n",
       "      <td>PKD_GCTGCAGCATGTGCTA-1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12668</th>\n",
       "      <td>PKD_CATTGAGGTCCAACGC-1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75143</th>\n",
       "      <td>Cont_GTTACGACAGCTGGTC-1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87188</th>\n",
       "      <td>Cont_CAACAACAGTGGAATT-1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41090</th>\n",
       "      <td>PKD_CCATAAGCATCGGTTA-1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60263</th>\n",
       "      <td>PKD_CACTAAGAGAAACCCG-1_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82386</th>\n",
       "      <td>Cont_GTAGAGGGTTTCACAG-1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>PKD_GTGTTAGCACGAAGAC-1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>Cont_TGATCAGGTGATTCTG-1_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46304 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name\n",
       "47294   PKD_ACGTAACCACTGCACG-1_6\n",
       "34455   PKD_GCTGCAGCATGTGCTA-1_4\n",
       "12668   PKD_CATTGAGGTCCAACGC-1_2\n",
       "75143  Cont_GTTACGACAGCTGGTC-1_2\n",
       "87188  Cont_CAACAACAGTGGAATT-1_4\n",
       "...                          ...\n",
       "41090   PKD_CCATAAGCATCGGTTA-1_5\n",
       "60263   PKD_CACTAAGAGAAACCCG-1_8\n",
       "82386  Cont_GTAGAGGGTTTCACAG-1_3\n",
       "6265    PKD_GTGTTAGCACGAAGAC-1_1\n",
       "76820  Cont_TGATCAGGTGATTCTG-1_2\n",
       "\n",
       "[46304 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_of_balanced_incices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88f9bbc2-a93f-4e0b-87c3-7fc333bb35e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<82168x27970 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 168492710 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_train_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2df3c19a-733a-4171-b30d-389742cb309a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a coo_matrix 'sparse_train_trans' and a DataFrame 'df_of_balanced_indices'\n",
    "# Convert the coo_matrix to a csr_matrix\n",
    "sparse_train_csr = csr_matrix(sparse_train_trans)\n",
    "\n",
    "# Create a boolean mask based on the indices in 'df_of_balanced_indices'\n",
    "mask = np.isin(np.arange(sparse_train_csr.shape[0]), df_of_balanced_incices.index)\n",
    "\n",
    "# Subset the csr_matrix using the boolean mask\n",
    "subset_sparse_train_csr = sparse_train_csr[mask]\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Assuming you have a 'subset_sparse_train_csr' csr_matrix\n",
    "subset_sparse_train_coo = subset_sparse_train_csr.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6905c8c9-12f1-4303-b336-973a0f57b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_sparse_train_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e7028-f3f5-4c6a-afa8-b72d9e8d6401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_and_pca_pipeline_trans = Pipeline([\n",
    "    ('cleaner', my_utils.DataClean(trans=True)),  # Specify that the data is transposed\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('pca', TruncatedSVD(n_components=2))\n",
    "])\n",
    "# Fit the pipeline to training\n",
    "clean_and_pca_pipeline_trans.fit(sparse_train_trans)\n",
    "# Transform the training data\n",
    "pca_sparse_train_trans = clean_and_pca_pipeline_trans.transform(subset_sparse_train_coo)\n",
    "pca_sparse_test_trans= clean_and_pca_pipeline_trans.transform(sparse_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4ca0a4-9d07-449d-9d49-fcc631f5d196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_sparse_train_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bc1af-6fe0-484d-b282-6b1ad7faba4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reindexer_trans = my_utils.Reindex(columns=[\"PC1\", \"PC2\"], names=row_names_trans, output_folder=\"../Output\", trans = True)\n",
    "train_pca_df_trans = reindexer_trans.transform(pca_sparse_train_trans, train_indices_trans, \"train\")\n",
    "test_pca_df_trans = reindexer_trans.transform(pca_sparse_test_trans, test_indices_trans, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5630326a-f418-4f58-bcec-4123d3586564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eda_pca = my_utils.DataEDAPCA(columns=[\"PC1\", \"PC2\"], trans = True, graphs = True)\n",
    "updated_train_pca_df_trans, metadata_removed, outlier_df_trans= eda_pca.fit_transform(train_pca_df_trans,another_df=  metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31160b-4bb3-4c60-ac8b-4bb9cb0e26af",
   "metadata": {},
   "source": [
    "Clustering on the Transposed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96013592-4483-4776-9d6d-ce4ef1dec211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pyarrow.parquet import read_table\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from memory_profiler import memory_usage\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import stats\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# You can also define custom functions, classes, and other code in this module.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdff41-6c21-4429-9c99-048e528bc931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def silhouette_scorer(estimator, X):\n",
    "    labels = estimator.fit_predict(X)\n",
    "    if len(set(labels)) == 1:\n",
    "        return 0  # Silhouette score is undefined for a single cluster\n",
    "    return silhouette_score(X, labels)\n",
    "\n",
    "def optimize_and_compare_hdbscan(data, hdbscan_params, alpha=0.05):\n",
    "    # Perform Grid Search\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=HDBSCAN(min_cluster_size=20),\n",
    "        param_grid=hdbscan_params,\n",
    "        scoring=silhouette_scorer,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(data)\n",
    "    grid_search_estimator = grid_search.best_estimator_\n",
    "\n",
    "    # Calculate silhouette scores for the default and grid search estimators\n",
    "    default_hdbscan = HDBSCAN(min_cluster_size=20).fit(data)\n",
    "    default_labels = default_hdbscan.labels_\n",
    "    default_silhouette_score = silhouette_score(data, default_labels)\n",
    "\n",
    "    grid_search_labels = grid_search_estimator.fit_predict(data)\n",
    "    grid_search_silhouette_score = silhouette_score(data, grid_search_labels)\n",
    "\n",
    "    # Check if the grid search estimator has a higher silhouette score\n",
    "    if grid_search_silhouette_score > default_silhouette_score:\n",
    "        # Perform a two-sample t-test\n",
    "        t_stat, p_value = stats.ttest_ind(default_labels, grid_search_labels)\n",
    "\n",
    "        # Check if the p-value is less than the significance level\n",
    "        if p_value < alpha:\n",
    "            choice = \"Grid Search Estimator\"\n",
    "        else:\n",
    "            choice = \"Default Parameter\"\n",
    "    else:\n",
    "        choice = \"Default Parameter\"\n",
    "\n",
    "    # Output informative print statements\n",
    "    print(\"Default HDBSCAN Silhouette Score:\", default_silhouette_score)\n",
    "    print(\"Grid Search Estimator Silhouette Score:\", grid_search_silhouette_score)\n",
    "\n",
    "    if grid_search_silhouette_score > default_silhouette_score:\n",
    "        if p_value < alpha:\n",
    "            print(\"The difference between the two groups is statistically significant.\")\n",
    "            print(f\"Using {choice} as it performs significantly better.\")\n",
    "        else:\n",
    "            print(\"The difference between the two groups is not statistically significant.\")\n",
    "            print(f\"Using {choice} as there is no significant improvement.\")\n",
    "    else:\n",
    "        print(\"Default Parameter has a higher silhouette score. No t-test performed.\")\n",
    "\n",
    "    return choice\n",
    "\n",
    "# Define the parameter grid for HDBSCAN\n",
    "hdbscan_params = {\n",
    "    'min_samples': [10, 30, 50, 60, 100],\n",
    "    'min_cluster_size': [100, 200, 300, 400, 500, 600],\n",
    "    'cluster_selection_method': ['eom', 'leaf'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Usage example with parameters\n",
    "result = optimize_and_compare_hdbscan(updated_train_pca_df_trans, hdbscan_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bffc18-714b-44ab-9ef9-cc2c21ce8ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
