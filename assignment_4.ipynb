{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe8befa-30dd-4af5-995f-a8309cdfe639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fd8c97-6e72-47c6-bee6-2a807d532e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_gz_file = 'GSE185948_count_RNA.rds.gz'\n",
    "output_rds_file = 'data_for_r.rds'\n",
    "\n",
    "# Open the compressed file and extract it\n",
    "with gzip.open(input_gz_file, 'rb') as f_in, open(output_rds_file, 'wb') as f_out:\n",
    "    shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(f'{input_gz_file} has been successfully uncompressed to {output_rds_file}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db12762e-d950-4f0d-88ae-cd32ec8e43ca",
   "metadata": {},
   "source": [
    "R code below"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea593dcf-f6ef-476e-97fa-5527db6fb58a",
   "metadata": {},
   "source": [
    "filename = file.choose()\n",
    "data = readRDS(filename)\n",
    "data\n",
    "sparse_matrix <- data\n",
    "\n",
    "num_columns <- ncol(sparse_matrix)\n",
    "# Get the nonzero elements and their indices\n",
    "nonzero_elements <- sparse_matrix@x\n",
    "row_indices <- sparse_matrix@i\n",
    "col_indices <- rep(1:num_columns, times = diff(sparse_matrix@p))  # Use sparse_matrix@j for column indices\n",
    "\n",
    "\n",
    "nonzero_data <- data.frame(row_indices, col_indices, nonzero_elements)\n",
    "\n",
    "col_names <- data.frame(sparse_matrix@Dimnames[2])\n",
    "nrow(col_names)\n",
    "row_names <- data.frame((sparse_matrix@Dimnames[1]))\n",
    "\n",
    "write.csv(row_names, 'row_names.csv')\n",
    "write.csv(col_names, 'col_names.csv')\n",
    "\n",
    "\n",
    "# Save the i, j information to a Parquet file\n",
    "write_parquet(nonzero_data, \"non_zero.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52d881cd-1a18-43f9-84d1-ff85e77ef9db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting memory_profiler\n",
      "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: psutil in /Users/jacksongazin/anaconda3/lib/python3.11/site-packages (from memory_profiler) (5.9.0)\n",
      "Installing collected packages: memory_profiler\n",
      "Successfully installed memory_profiler-0.61.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ca90420-40cf-490b-8623-55e02e82e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyarrow.parquet import read_table\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from memory_profiler import memory_usage\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from kneed import KneeLocator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import stats\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f82c6cb-0db4-42d6-b286-e191ff5421c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(data_path, row_info_path, column_info_path):\n",
    "    # Load non_zero parquet data\n",
    "    table = read_table(data_path)\n",
    "    nonzero_data = table.to_pandas()\n",
    "    \n",
    "    # Adjust column indices to be 0-based\n",
    "    nonzero_data['col_indices'] = nonzero_data['col_indices'] - 1\n",
    "    \n",
    "    # Load row and column index info\n",
    "    rows = pd.read_csv(row_info_path)\n",
    "    row_names = rows.iloc[:, 1].to_list()\n",
    "    \n",
    "    columns = pd.read_csv(column_info_path)\n",
    "    column_names = columns.iloc[:, 1].to_list()\n",
    "    \n",
    "    # Convert the sparse matrix to a dense DataFrame\n",
    "    sparse_matrix = coo_matrix(\n",
    "        (nonzero_data['nonzero_elements'], (nonzero_data['row_indices'], nonzero_data['col_indices'])),\n",
    "        shape=(len(row_names), len(column_names))\n",
    "    )\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    print('Returning sparse_matrix, column_names, and row_names')\n",
    "    \n",
    "    return sparse_matrix, column_names, row_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b59b345-8cff-4d3c-9531-5360b4816153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NormalizerSparseMatrix(TransformerMixin, BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        # This method should typically be used to perform any necessary setup, but it's not needed for this transformer.\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # You can use the normalize function here\n",
    "        sparse_matrix_norm = normalize(X, norm='l1', axis=1)\n",
    "        return sparse_matrix_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b90e572-f7b3-41b5-ae96-ea924ade20ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning sparse_matrix, column_names, and row_names\n"
     ]
    }
   ],
   "source": [
    "data_path = 'non_zero.parquet'\n",
    "row_info_path = 'row_names.csv'\n",
    "column_info_path = 'col_names.csv'\n",
    "#sparse_matrix = coo_matrix((data['nonzero_elements'], (data['row_indices'], data['col_indices'])))\n",
    "sparse_matrix, row_names, column_names = load_data(data_path, row_info_path, column_info_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "089b4296-80cc-4e83-918e-017fbb1efe56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row_indices = np.arange(sparse_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9100d53e-5566-4ecd-b057-6d71528fc20f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sparse_train, sparse_test, train_indices, test_indices = train_test_split(\n",
    "    sparse_matrix, row_indices, test_size=0.2, random_state=42\n",
    ")\n",
    "del sparse_matrix\n",
    "del row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88adbcba-aedb-4342-90cb-40479b140e84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_row_names = [row_names[i] for i in train_indices]\n",
    "test_row_names = [row_names[i] for i in test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "793fa46a-290a-48f6-857f-7bedcc7248ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler(with_mean=False)),\n",
    "        ('normalizer', NormalizerSparseMatrix()),\n",
    "        ('pca', TruncatedSVD(n_components=2))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54c8deb3-28b6-4655-818b-c4d06b5c0339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.fit(sparse_train)\n",
    "\n",
    "# Transform the training data\n",
    "pca_sparse_train = pipeline.transform(sparse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "101f88bf-0fe6-4cd1-89ab-de8f822454d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_sparse_test = pipeline.transform(sparse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4be59ee-221e-47f9-99dd-55ac83261660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pca_df = pd.DataFrame(pca_sparse_train, columns=[\"PC1\", \"PC2\"], index=train_row_names)\n",
    "test_pca_df = pd.DataFrame(pca_sparse_test, columns=[\"PC1\", \"PC2\"], index=test_row_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "faf29ccd-6d7c-4571-a752-0cdf17399b34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PKD_CATCGCTCACTCAGAT-1_3</th>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GGACGTCGTATGGGAC-1_2</th>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_AGTACTGCAATGCAGG-1_3</th>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_CTGCCATTCTTCGTAT-1_2</th>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_CAGCAATAGTCGGCCT-1_3</th>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_ATCCTATGTTCCTAGA-1_3</th>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GGCTGTGAGGAACGAA-1_1</th>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_AGGCCACCACAACCGC-1_1</th>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GGAATGGAGCCAAGGT-1_2</th>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_CGTTGGGGTGTTAACC-1_3</th>\n",
       "      <td>-0.000050</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22376 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               PC1       PC2\n",
       "PKD_CATCGCTCACTCAGAT-1_3 -0.000021  0.000028\n",
       "PKD_GGACGTCGTATGGGAC-1_2 -0.000012  0.000142\n",
       "PKD_AGTACTGCAATGCAGG-1_3 -0.000013  0.000023\n",
       "PKD_CTGCCATTCTTCGTAT-1_2 -0.000013  0.000063\n",
       "PKD_CAGCAATAGTCGGCCT-1_3 -0.000016  0.000614\n",
       "...                            ...       ...\n",
       "PKD_ATCCTATGTTCCTAGA-1_3  0.000235  0.000037\n",
       "PKD_GGCTGTGAGGAACGAA-1_1 -0.000005  0.000027\n",
       "PKD_AGGCCACCACAACCGC-1_1 -0.000011  0.000147\n",
       "PKD_GGAATGGAGCCAAGGT-1_2 -0.000012  0.000043\n",
       "PKD_CGTTGGGGTGTTAACC-1_3 -0.000050  0.000034\n",
       "\n",
       "[22376 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e38d0e6-8adb-421a-a7dd-5b5d1df809a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PKD_CTCATCGGTTACACAC-1_2</th>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GTATTGGTCCCAATAG-1_3</th>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.001408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_TCCTGCAAGGACGCTA-1_2</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GACTGATAGCACACCC-1_2</th>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GGGTCACAGTCATCGT-1_2</th>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GGGAAGTTCAAGCTTG-1_3</th>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_CATCGGGGTAGGGAGG-1_3</th>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_TCCCAGTTCAGTCCGG-1_1</th>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_TGTAGACCACCGGCTA-1_1</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GATGCTAGTTACACAC-1_2</th>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5594 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               PC1       PC2\n",
       "PKD_CTCATCGGTTACACAC-1_2 -0.000013  0.000027\n",
       "PKD_GTATTGGTCCCAATAG-1_3  0.000133  0.001408\n",
       "PKD_TCCTGCAAGGACGCTA-1_2  0.000083  0.000034\n",
       "PKD_GACTGATAGCACACCC-1_2 -0.000009  0.000061\n",
       "PKD_GGGTCACAGTCATCGT-1_2 -0.000021  0.000022\n",
       "...                            ...       ...\n",
       "PKD_GGGAAGTTCAAGCTTG-1_3 -0.000015  0.000021\n",
       "PKD_CATCGGGGTAGGGAGG-1_3 -0.000018  0.000021\n",
       "PKD_TCCCAGTTCAGTCCGG-1_1 -0.000011  0.000032\n",
       "PKD_TGTAGACCACCGGCTA-1_1  0.000004  0.000029\n",
       "PKD_GATGCTAGTTACACAC-1_2 -0.000024  0.000076\n",
       "\n",
       "[5594 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f89030df-69c1-4f7d-a283-2de6f98e73ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pca_df.to_csv('train_pca_df.csv')\n",
    "test_pca_df.to_csv('test_pca_df.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732968b-22a1-4c8a-9fab-057d6c4742b7",
   "metadata": {},
   "source": [
    "## Clustering on the Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc99e243-03cf-485a-9d18-2e2f960e8779",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default KMeans Silhouette Score: 0.9994378015167469\n",
      "Grid Search Estimator Silhouette Score: 0.9614417750317619\n",
      "The difference between the two groups is statistically significant.\n",
      "Using Grid Search Estimator as it performs significantly better using a threshold of alpha = .05 .\n"
     ]
    }
   ],
   "source": [
    "def optimize_and_compare_kmeans(data, kmeans_params, alpha=0.05):\n",
    "    # Perform Grid Search\n",
    "    grid = GridSearchCV(KMeans(), kmeans_params, cv=3, refit=True)\n",
    "    grid.fit(data)\n",
    "    grid_search_estimator = grid.best_estimator_\n",
    "\n",
    "    # Calculate silhouette scores\n",
    "    default_kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(data)\n",
    "    default_silhouette_score = silhouette_score(data, default_kmeans.labels_)\n",
    "    grid_search_silhouette_score = silhouette_score(data, grid_search_estimator.labels_)\n",
    "\n",
    "    # Perform a two-sample t-test\n",
    "    t_stat, p_value = stats.ttest_ind(default_kmeans.labels_, grid_search_estimator.labels_)\n",
    "\n",
    "    # Set the default choice to \"Grid Search Estimator\"\n",
    "    choice = \"Grid Search Estimator\"\n",
    "\n",
    "    # Check if the p-value is less than the significance level\n",
    "    if p_value < alpha:\n",
    "        choice = \"Grid Search Estimator\"\n",
    "    else:\n",
    "        choice = \"Default Parameter\"\n",
    "\n",
    "    # Output informative print statements\n",
    "    print(\"Default KMeans Silhouette Score:\", default_silhouette_score)\n",
    "    print(\"Grid Search Estimator Silhouette Score:\", grid_search_silhouette_score)\n",
    "\n",
    "    if p_value < alpha:\n",
    "        print(\"The difference between the two groups is statistically significant.\")\n",
    "        print(f\"Using {choice} as it performs significantly better using a threshold of alpha = .05 .\")\n",
    "    else:\n",
    "        print(\"The difference between the two groups is not statistically significant.\")\n",
    "        print(f\"Using {choice} as there is no significant improvement using a threshold of alpha = .05.\")\n",
    "\n",
    "    return choice\n",
    "\n",
    "# Usage example with parameters\n",
    "kmeans_params = {\n",
    "    'n_clusters': list(range(1, 10)),\n",
    "    'init': ['random', 'k-means++'],\n",
    "    'n_init': [1, 5, 10],\n",
    "    'max_iter': [300],\n",
    "    'random_state': [0]\n",
    "}\n",
    "result = optimize_and_compare_kmeans(sparse_train_pca_df, kmeans_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f619b-9ff6-4f40-bbf7-b3250eb2d0f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ddcd827-c720-4a8e-b0de-e3307758c645",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default HDBSCAN Silhouette Score: 0.35331779854940065\n",
      "Grid Search Estimator Silhouette Score: -0.7423886873259252\n",
      "The difference between the two groups is statistically significant.\n",
      "Using Grid Search Estimator as it performs significantly better.\n"
     ]
    }
   ],
   "source": [
    "def silhouette_scorer(estimator, X):\n",
    "    labels = estimator.fit_predict(X)\n",
    "    if len(set(labels)) == 1:\n",
    "        return 0  # Silhouette score is undefined for a single cluster\n",
    "    return silhouette_score(X, labels)\n",
    "\n",
    "def optimize_and_compare_hdbscan(data, hdbscan_params, alpha=0.05):\n",
    "    # Perform Grid Search\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=HDBSCAN(min_cluster_size=20),\n",
    "        param_grid=hdbscan_params,\n",
    "        scoring=silhouette_scorer,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(data)\n",
    "    grid_search_estimator = grid_search.best_estimator_\n",
    "\n",
    "    # Calculate silhouette scores for the default and grid search estimators\n",
    "    default_hdbscan = HDBSCAN(min_cluster_size=20).fit(data)\n",
    "    default_labels = default_hdbscan.labels_\n",
    "    default_silhouette_score = silhouette_score(data, default_labels)\n",
    "\n",
    "    grid_search_labels = grid_search_estimator.fit_predict(data)\n",
    "    grid_search_silhouette_score = silhouette_score(data, grid_search_labels)\n",
    "\n",
    "    # Perform a two-sample t-test\n",
    "    t_stat, p_value = stats.ttest_ind(default_labels, grid_search_labels)\n",
    "\n",
    "    # Set the default choice to \"Grid Search Estimator\"\n",
    "    choice = \"Grid Search Estimator\"\n",
    "\n",
    "    # Check if the p-value is less than the significance level\n",
    "    if p_value < alpha:\n",
    "        choice = \"Grid Search Estimator\"\n",
    "    else:\n",
    "        choice = \"Default Parameter\"\n",
    "\n",
    "    # Output informative print statements\n",
    "    print(\"Default HDBSCAN Silhouette Score:\", default_silhouette_score)\n",
    "    print(\"Grid Search Estimator Silhouette Score:\", grid_search_silhouette_score)\n",
    "\n",
    "    if p_value < alpha:\n",
    "        print(\"The difference between the two groups is statistically significant.\")\n",
    "        print(f\"Using {choice} as it performs significantly better.\")\n",
    "    else:\n",
    "        print(\"The difference between the two groups is not statistically significant.\")\n",
    "        print(f\"Using {choice} as there is no significant improvement.\")\n",
    "\n",
    "    return choice\n",
    "\n",
    "# Define the parameter grid for HDBSCAN\n",
    "hdbscan_params = {\n",
    "    'min_samples': [10, 30, 50, 60, 100],\n",
    "    'min_cluster_size': [100, 200, 300, 400, 500, 600],\n",
    "    'cluster_selection_method': ['eom', 'leaf'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Usage example with parameters\n",
    "result = optimize_and_compare_hdbscan(sparse_train_pca_df, hdbscan_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e22a4c4-a081-4085-92c8-e0c7b13a00ce",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/tuning-with-hdbscan-149865ac2970"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076af96-9d6f-4f0e-afa9-383cd9a3ea03",
   "metadata": {},
   "source": [
    "Things to consider\n",
    "\n",
    "\n",
    "1) Get the clustering to work in a pipeline\n",
    "2) Are these ok default parameters\n",
    "3) What to do with the test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8994a0-8a6b-41c9-b3f1-e96d5c8a40ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
