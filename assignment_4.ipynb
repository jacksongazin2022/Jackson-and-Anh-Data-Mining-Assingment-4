{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe8befa-30dd-4af5-995f-a8309cdfe639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fd8c97-6e72-47c6-bee6-2a807d532e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_gz_file = 'GSE185948_count_RNA.rds.gz'\n",
    "output_rds_file = 'data_for_r.rds'\n",
    "\n",
    "# Open the compressed file and extract it\n",
    "with gzip.open(input_gz_file, 'rb') as f_in, open(output_rds_file, 'wb') as f_out:\n",
    "    shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(f'{input_gz_file} has been successfully uncompressed to {output_rds_file}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db12762e-d950-4f0d-88ae-cd32ec8e43ca",
   "metadata": {},
   "source": [
    "R code below"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea593dcf-f6ef-476e-97fa-5527db6fb58a",
   "metadata": {},
   "source": [
    "filename = file.choose()\n",
    "data = readRDS(filename)\n",
    "data\n",
    "sparse_matrix <- data\n",
    "\n",
    "num_columns <- ncol(sparse_matrix)\n",
    "# Get the nonzero elements and their indices\n",
    "nonzero_elements <- sparse_matrix@x\n",
    "row_indices <- sparse_matrix@i\n",
    "col_indices <- rep(1:num_columns, times = diff(sparse_matrix@p))  # Use sparse_matrix@j for column indices\n",
    "\n",
    "\n",
    "nonzero_data <- data.frame(row_indices, col_indices, nonzero_elements)\n",
    "\n",
    "col_names <- data.frame(sparse_matrix@Dimnames[2])\n",
    "nrow(col_names)\n",
    "row_names <- data.frame((sparse_matrix@Dimnames[1]))\n",
    "\n",
    "write.csv(row_names, 'row_names.csv')\n",
    "write.csv(col_names, 'col_names.csv')\n",
    "\n",
    "\n",
    "# Save the i, j information to a Parquet file\n",
    "write_parquet(nonzero_data, \"non_zero.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52d881cd-1a18-43f9-84d1-ff85e77ef9db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting memory_profiler\n",
      "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: psutil in /Users/jacksongazin/anaconda3/lib/python3.11/site-packages (from memory_profiler) (5.9.0)\n",
      "Installing collected packages: memory_profiler\n",
      "Successfully installed memory_profiler-0.61.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca90420-40cf-490b-8623-55e02e82e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyarrow.parquet import read_table\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from memory_profiler import memory_usage\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from kneed import KneeLocator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import stats\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f82c6cb-0db4-42d6-b286-e191ff5421c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(data_path, row_info_path, column_info_path):\n",
    "    # Load non_zero parquet data\n",
    "    table = read_table(data_path)\n",
    "    nonzero_data = table.to_pandas()\n",
    "    \n",
    "    # Adjust column indices to be 0-based\n",
    "    nonzero_data['col_indices'] = nonzero_data['col_indices'] - 1\n",
    "    \n",
    "    # Load row and column index info\n",
    "    rows = pd.read_csv(row_info_path)\n",
    "    row_names = rows.iloc[:, 1].to_list()\n",
    "    \n",
    "    columns = pd.read_csv(column_info_path)\n",
    "    column_names = columns.iloc[:, 1].to_list()\n",
    "    \n",
    "    # Convert the sparse matrix to a dense DataFrame\n",
    "    sparse_matrix = coo_matrix(\n",
    "        (nonzero_data['nonzero_elements'], (nonzero_data['row_indices'], nonzero_data['col_indices'])),\n",
    "        shape=(len(row_names), len(column_names))\n",
    "    )\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    print('Returning sparse_matrix, column_names, and row_names')\n",
    "    \n",
    "    return sparse_matrix, column_names, row_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b90e572-f7b3-41b5-ae96-ea924ade20ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning sparse_matrix, column_names, and row_names\n"
     ]
    }
   ],
   "source": [
    "data_path = 'non_zero.parquet'\n",
    "row_info_path = 'row_names.csv'\n",
    "column_info_path = 'col_names.csv'\n",
    "#sparse_matrix = coo_matrix((data['nonzero_elements'], (data['row_indices'], data['col_indices'])))\n",
    "sparse_matrix, row_names, column_names = load_data(data_path, row_info_path, column_info_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "089b4296-80cc-4e83-918e-017fbb1efe56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row_indices = np.arange(sparse_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9100d53e-5566-4ecd-b057-6d71528fc20f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sparse_train, sparse_test, train_indices, test_indices = train_test_split(\n",
    "    sparse_matrix, row_indices, test_size=0.2, random_state=42\n",
    ")\n",
    "del sparse_matrix\n",
    "del row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88adbcba-aedb-4342-90cb-40479b140e84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_row_names = [row_names[i] for i in train_indices]\n",
    "test_row_names = [row_names[i] for i in test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793fa46a-290a-48f6-857f-7bedcc7248ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler(with_mean = False)),\n",
    "        ('pca', TruncatedSVD(n_components=2))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54c8deb3-28b6-4655-818b-c4d06b5c0339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.fit(sparse_train)\n",
    "\n",
    "# Transform the training data\n",
    "pca_sparse_train = pipeline.transform(sparse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "101f88bf-0fe6-4cd1-89ab-de8f822454d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_sparse_test = pipeline.transform(sparse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4be59ee-221e-47f9-99dd-55ac83261660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pca_df = pd.DataFrame(pca_sparse_train, columns=[\"PC1\", \"PC2\"], index=train_row_names)\n",
    "test_pca_df = pd.DataFrame(pca_sparse_test, columns=[\"PC1\", \"PC2\"], index=test_row_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faf29ccd-6d7c-4571-a752-0cdf17399b34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PKD_CATCGCTCACTCAGAT-1_3</th>\n",
       "      <td>3.297208</td>\n",
       "      <td>-0.093384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GGACGTCGTATGGGAC-1_2</th>\n",
       "      <td>1.092518</td>\n",
       "      <td>-0.574449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_AGTACTGCAATGCAGG-1_3</th>\n",
       "      <td>2.110547</td>\n",
       "      <td>-1.040423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_CTGCCATTCTTCGTAT-1_2</th>\n",
       "      <td>269.334105</td>\n",
       "      <td>-184.999588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_CAGCAATAGTCGGCCT-1_3</th>\n",
       "      <td>0.138904</td>\n",
       "      <td>-0.014087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_ATCCTATGTTCCTAGA-1_3</th>\n",
       "      <td>39.704073</td>\n",
       "      <td>-17.631512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GGCTGTGAGGAACGAA-1_1</th>\n",
       "      <td>29.823898</td>\n",
       "      <td>-15.172676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_AGGCCACCACAACCGC-1_1</th>\n",
       "      <td>83.125263</td>\n",
       "      <td>-6.222054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GGAATGGAGCCAAGGT-1_2</th>\n",
       "      <td>18.421691</td>\n",
       "      <td>-10.114604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_CGTTGGGGTGTTAACC-1_3</th>\n",
       "      <td>0.045995</td>\n",
       "      <td>-0.046312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22376 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 PC1         PC2\n",
       "PKD_CATCGCTCACTCAGAT-1_3    3.297208   -0.093384\n",
       "PKD_GGACGTCGTATGGGAC-1_2    1.092518   -0.574449\n",
       "PKD_AGTACTGCAATGCAGG-1_3    2.110547   -1.040423\n",
       "PKD_CTGCCATTCTTCGTAT-1_2  269.334105 -184.999588\n",
       "PKD_CAGCAATAGTCGGCCT-1_3    0.138904   -0.014087\n",
       "...                              ...         ...\n",
       "PKD_ATCCTATGTTCCTAGA-1_3   39.704073  -17.631512\n",
       "PKD_GGCTGTGAGGAACGAA-1_1   29.823898  -15.172676\n",
       "PKD_AGGCCACCACAACCGC-1_1   83.125263   -6.222054\n",
       "PKD_GGAATGGAGCCAAGGT-1_2   18.421691  -10.114604\n",
       "PKD_CGTTGGGGTGTTAACC-1_3    0.045995   -0.046312\n",
       "\n",
       "[22376 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e38d0e6-8adb-421a-a7dd-5b5d1df809a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PKD_CTCATCGGTTACACAC-1_2</th>\n",
       "      <td>69.309507</td>\n",
       "      <td>-36.936357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GTATTGGTCCCAATAG-1_3</th>\n",
       "      <td>0.051566</td>\n",
       "      <td>-0.035225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_TCCTGCAAGGACGCTA-1_2</th>\n",
       "      <td>81.411556</td>\n",
       "      <td>-31.177147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GACTGATAGCACACCC-1_2</th>\n",
       "      <td>15.758585</td>\n",
       "      <td>-6.156989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GGGTCACAGTCATCGT-1_2</th>\n",
       "      <td>1.104429</td>\n",
       "      <td>-0.615846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GGGAAGTTCAAGCTTG-1_3</th>\n",
       "      <td>0.111826</td>\n",
       "      <td>-0.023407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_CATCGGGGTAGGGAGG-1_3</th>\n",
       "      <td>0.236129</td>\n",
       "      <td>0.025927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_TCCCAGTTCAGTCCGG-1_1</th>\n",
       "      <td>27.622148</td>\n",
       "      <td>-9.551978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_TGTAGACCACCGGCTA-1_1</th>\n",
       "      <td>12.683483</td>\n",
       "      <td>-5.135039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKD_GATGCTAGTTACACAC-1_2</th>\n",
       "      <td>11.842110</td>\n",
       "      <td>-7.831853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5594 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                PC1        PC2\n",
       "PKD_CTCATCGGTTACACAC-1_2  69.309507 -36.936357\n",
       "PKD_GTATTGGTCCCAATAG-1_3   0.051566  -0.035225\n",
       "PKD_TCCTGCAAGGACGCTA-1_2  81.411556 -31.177147\n",
       "PKD_GACTGATAGCACACCC-1_2  15.758585  -6.156989\n",
       "PKD_GGGTCACAGTCATCGT-1_2   1.104429  -0.615846\n",
       "...                             ...        ...\n",
       "PKD_GGGAAGTTCAAGCTTG-1_3   0.111826  -0.023407\n",
       "PKD_CATCGGGGTAGGGAGG-1_3   0.236129   0.025927\n",
       "PKD_TCCCAGTTCAGTCCGG-1_1  27.622148  -9.551978\n",
       "PKD_TGTAGACCACCGGCTA-1_1  12.683483  -5.135039\n",
       "PKD_GATGCTAGTTACACAC-1_2  11.842110  -7.831853\n",
       "\n",
       "[5594 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f89030df-69c1-4f7d-a283-2de6f98e73ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pca_df.to_csv('train_pca_df.csv')\n",
    "test_pca_df.to_csv('test_pca_df.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732968b-22a1-4c8a-9fab-057d6c4742b7",
   "metadata": {},
   "source": [
    "## Clustering on the Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc99e243-03cf-485a-9d18-2e2f960e8779",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Parameter has a higher Silhouette Score.\n",
      "Using Default Parameter as it performs better based on Silhouette Score.\n"
     ]
    }
   ],
   "source": [
    "def optimize_and_compare_kmeans(data, kmeans_params, alpha=0.05):\n",
    "    # Perform Grid Search\n",
    "    grid = GridSearchCV(KMeans(), kmeans_params, cv=3, refit=True)\n",
    "    grid.fit(data)\n",
    "    grid_search_estimator = grid.best_estimator_\n",
    "\n",
    "    # Calculate silhouette scores\n",
    "    default_kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(data)\n",
    "    default_silhouette_score = silhouette_score(data, default_kmeans.labels_)\n",
    "    grid_search_silhouette_score = silhouette_score(data, grid_search_estimator.labels_)\n",
    "\n",
    "    # Perform a two-sample t-test only if Grid Search performs better\n",
    "    if grid_search_silhouette_score > default_silhouette_score:\n",
    "        t_stat, p_value = stats.ttest_ind(default_kmeans.labels_, grid_search_estimator.labels_)\n",
    "\n",
    "        # Set the default choice to \"Grid Search Estimator\"\n",
    "        choice = \"Grid Search Estimator\"\n",
    "\n",
    "        # Output informative print statements\n",
    "        print(\"Default KMeans Silhouette Score:\", default_silhouette_score)\n",
    "        print(\"Grid Search Estimator Silhouette Score:\", grid_search_silhouette_score)\n",
    "\n",
    "        if p_value < alpha:\n",
    "            print(\"The difference between the two groups is statistically significant.\")\n",
    "            print(f\"Using {choice} as it performs significantly better using a threshold of alpha = .05 .\")\n",
    "        else:\n",
    "            print(\"The difference between the two groups is not statistically significant.\")\n",
    "            print(f\"Using {choice} as there is no significant improvement using a threshold of alpha = .05.\")\n",
    "    else:\n",
    "        choice = \"Default Parameter\"\n",
    "        print(\"Default Parameter has a higher Silhouette Score.\")\n",
    "        print(\"Using Default Parameter as it performs better based on Silhouette Score.\")\n",
    "\n",
    "    return choice\n",
    "\n",
    "# Usage example with parameters\n",
    "kmeans_params = {\n",
    "    'n_clusters': list(range(1, 10)),\n",
    "    'init': ['random', 'k-means++'],\n",
    "    'n_init': [1, 5, 10],\n",
    "    'max_iter': [300],\n",
    "    'random_state': [0]\n",
    "}\n",
    "result = optimize_and_compare_kmeans(train_pca_df, kmeans_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f619b-9ff6-4f40-bbf7-b3250eb2d0f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddcd827-c720-4a8e-b0de-e3307758c645",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sparse_train_pca_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 61\u001b[0m\n\u001b[1;32m     53\u001b[0m hdbscan_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m100\u001b[39m],\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_cluster_size\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m600\u001b[39m],\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_selection_method\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleaf\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanhattan\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     58\u001b[0m }\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Usage example with parameters\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m result \u001b[38;5;241m=\u001b[39m optimize_and_compare_hdbscan(sparse_train_pca_df, hdbscan_params)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sparse_train_pca_df' is not defined"
     ]
    }
   ],
   "source": [
    "def silhouette_scorer(estimator, X):\n",
    "    labels = estimator.fit_predict(X)\n",
    "    if len(set(labels)) == 1:\n",
    "        return 0  # Silhouette score is undefined for a single cluster\n",
    "    return silhouette_score(X, labels)\n",
    "\n",
    "def optimize_and_compare_hdbscan(data, hdbscan_params, alpha=0.05):\n",
    "    # Perform Grid Search\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=HDBSCAN(min_cluster_size=20),\n",
    "        param_grid=hdbscan_params,\n",
    "        scoring=silhouette_scorer,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(data)\n",
    "    grid_search_estimator = grid_search.best_estimator_\n",
    "\n",
    "    # Calculate silhouette scores for the default and grid search estimators\n",
    "    default_hdbscan = HDBSCAN(min_cluster_size=20).fit(data)\n",
    "    default_labels = default_hdbscan.labels_\n",
    "    default_silhouette_score = silhouette_score(data, default_labels)\n",
    "\n",
    "    grid_search_labels = grid_search_estimator.fit_predict(data)\n",
    "    grid_search_silhouette_score = silhouette_score(data, grid_search_labels)\n",
    "\n",
    "    # Perform a two-sample t-test\n",
    "    t_stat, p_value = stats.ttest_ind(default_labels, grid_search_labels)\n",
    "\n",
    "    # Set the default choice to \"Grid Search Estimator\"\n",
    "    choice = \"Grid Search Estimator\"\n",
    "\n",
    "    # Check if the p-value is less than the significance level\n",
    "    if p_value < alpha:\n",
    "        choice = \"Grid Search Estimator\"\n",
    "    else:\n",
    "        choice = \"Default Parameter\"\n",
    "\n",
    "    # Output informative print statements\n",
    "    print(\"Default HDBSCAN Silhouette Score:\", default_silhouette_score)\n",
    "    print(\"Grid Search Estimator Silhouette Score:\", grid_search_silhouette_score)\n",
    "\n",
    "    if p_value < alpha:\n",
    "        print(\"The difference between the two groups is statistically significant.\")\n",
    "        print(f\"Using {choice} as it performs significantly better.\")\n",
    "    else:\n",
    "        print(\"The difference between the two groups is not statistically significant.\")\n",
    "        print(f\"Using {choice} as there is no significant improvement.\")\n",
    "\n",
    "    return choice\n",
    "\n",
    "# Define the parameter grid for HDBSCAN\n",
    "hdbscan_params = {\n",
    "    'min_samples': [10, 30, 50, 60, 100],\n",
    "    'min_cluster_size': [100, 200, 300, 400, 500, 600],\n",
    "    'cluster_selection_method': ['eom', 'leaf'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Usage example with parameters\n",
    "result = optimize_and_compare_hdbscan(sparse_train_pca_df, hdbscan_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e22a4c4-a081-4085-92c8-e0c7b13a00ce",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/tuning-with-hdbscan-149865ac2970"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076af96-9d6f-4f0e-afa9-383cd9a3ea03",
   "metadata": {},
   "source": [
    "Things to consider\n",
    "\n",
    "\n",
    "1) Get the clustering to work in a pipeline\n",
    "2) Are these ok default parameters\n",
    "3) What to do with the test data\n",
    "4) Should we be using silhoute on grid search or should i be optimizaing it differently\n",
    "5) Are we normalizing it the right way? Since normalize is working along rows is this dealing with out of domain sampels?\n",
    "6) Make it so it put things in folders\n",
    "7) Quality check NAS? How do to this with a sparse matrix\n",
    "8) Do soemthing like she did in notebook 3 to label the data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8994a0-8a6b-41c9-b3f1-e96d5c8a40ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
